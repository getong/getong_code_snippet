* libp2p code reading

** NetworkBehaviour

#+begin_src rust
impl NetworkBehaviour for Behaviour {
    type ConnectionHandler = Handler;
    type ToSwarm = ();

    fn handle_established_inbound_connection(
        &mut self,
        connection_id: ConnectionId,
        peer: PeerId,
        _: &Multiaddr,
        _: &Multiaddr,
    ) -> Result<THandler<Self>, ConnectionDenied> {
        Ok(Handler::new(
            peer,
            self.shared.clone(),
            Shared::lock(&self.shared).receiver(peer, connection_id),
        ))
    }

    fn handle_established_outbound_connection(
        &mut self,
        connection_id: ConnectionId,
        peer: PeerId,
        _: &Multiaddr,
        _: Endpoint,
    ) -> Result<THandler<Self>, ConnectionDenied> {
        Ok(Handler::new(
            peer,
            self.shared.clone(),
            Shared::lock(&self.shared).receiver(peer, connection_id),
        ))
    }

    fn on_swarm_event(&mut self, event: FromSwarm) {
        match event {
            FromSwarm::ConnectionEstablished(ConnectionEstablished {
                peer_id,
                connection_id,
                ..
            }) => Shared::lock(&self.shared).on_connection_established(connection_id, peer_id),
            FromSwarm::ConnectionClosed(ConnectionClosed { connection_id, .. }) => {
                Shared::lock(&self.shared).on_connection_closed(connection_id)
            }
            FromSwarm::DialFailure(DialFailure {
                peer_id: Some(peer_id),
                error:
                    error @ (DialError::Transport(_)
                    | DialError::Denied { .. }
                    | DialError::NoAddresses
                    | DialError::WrongPeerId { .. }),
                ..
            }) => {
                let reason = error.to_string(); // We can only forward the string repr but it is better than nothing.

                Shared::lock(&self.shared).on_dial_failure(peer_id, reason)
            }
            _ => {}
        }
    }

    fn on_connection_handler_event(
        &mut self,
        _peer_id: PeerId,
        _connection_id: ConnectionId,
        event: THandlerOutEvent<Self>,
    ) {
        void::unreachable(event);
    }

    fn poll(
        &mut self,
        cx: &mut Context<'_>,
    ) -> Poll<ToSwarm<Self::ToSwarm, THandlerInEvent<Self>>> {
        if let Poll::Ready(Some(peer)) = self.dial_receiver.poll_next_unpin(cx) {
            return Poll::Ready(ToSwarm::Dial {
                opts: DialOpts::peer_id(peer)
                    .condition(PeerCondition::DisconnectedAndNotDialing)
                    .build(),
            });
        }

        Poll::Pending
    }
}
#+end_src

The NetworkBehaviour is trait for network communication, and Behaviour stores the basic info.


** tokio::select and swarm.select_next_some() example

#+begin_src rust
pub async fn init_p2p_client(server_ip_address: String) -> Result<(), Box<dyn Error>> {
    // env_logger::init();

    let key_pair = identity::Keypair::generate_ed25519();
    let rendezvous_point_address = format!("/ip4/{}/tcp/62649", server_ip_address).as_str().parse::<Multiaddr>().unwrap();
    // let rendezvous_point = "12D3KooWDpJ7As7BWAwRMfu1VU2WCqNjvq387JEYKDBj4kx6nXTN".parse().unwrap();

    let mut swarm = SwarmBuilder::with_tokio_executor(
        tcp::tokio::Transport::default()
            .upgrade(Version::V1Lazy)
            .authenticate(noise::Config::new(&key_pair).unwrap())
            .multiplex(yamux::Config::default())
            .boxed(),
        MyBehaviour {
            identify: identify::Behaviour::new(identify::Config::new(
                "rendezvous-example/1.0.0".to_string(),
                key_pair.public(),
            )),
            rendezvous: rendezvous::client::Behaviour::new(key_pair.clone()),
            ping: ping::Behaviour::new(ping::Config::new().with_interval(Duration::from_secs(1))),
            keep_alive: keep_alive::Behaviour,
        },
        PeerId::from(key_pair.public()),
    )
    .build();

    let external_address = format!("/ip4/{}/tcp/62649", server_ip_address).as_str().parse::<Multiaddr>().unwrap();
    swarm.add_external_address(external_address, libp2p::swarm::AddressScore::Infinite);

    log::warn!("Local peer id: {}", swarm.local_peer_id());

    swarm.dial(rendezvous_point_address.clone()).unwrap();

    let mut discover_tick = tokio::time::interval(Duration::from_secs(30));
    let mut cookie = None;

    loop {
        tokio::select! {
                event = swarm.select_next_some() => match event {
                    SwarmEvent::ConnectionEstablished { peer_id, .. } => {
                        log::warn!(
                            "Connected to rendezvous point, discovering nodes in '{}' namespace ...",
                            NAMESPACE
                        );

                        swarm.behaviour_mut().rendezvous.discover(
                            Some(rendezvous::Namespace::new(NAMESPACE.to_string()).unwrap()),
                            None,
                            None,
                            peer_id,
                        );

                        swarm.behaviour_mut().rendezvous.register(
                            rendezvous::Namespace::from_static("rendezvous"),
                            peer_id,
                            None,
                        );

                        log::warn!("Connection established with rendezvous point {}", peer_id);
                    }
                    SwarmEvent::Behaviour(MyBehaviourEvent::Rendezvous(rendezvous::client::Event::Discovered {
                        registrations,
                        cookie: new_cookie,
                        ..
                    })) => {
                        cookie.replace(new_cookie);

                        for registration in registrations {
                            for address in registration.record.addresses() {
                                let peer = registration.record.peer_id();
                                log::warn!("Discovered peer {} at {}", peer, address);

                                let p2p_suffix = Protocol::P2p(*peer.as_ref());
                                let address_with_p2p =
                                    if !address.ends_with(&Multiaddr::empty().with(p2p_suffix.clone())) {
                                        address.clone().with(p2p_suffix)
                                    } else {
                                        address.clone()
                                    };

                                swarm.dial(address_with_p2p).unwrap();
                            }
                        }
                    }
                    SwarmEvent::Behaviour(MyBehaviourEvent::Identify(identify::Event::Received {
                        peer_id, info, ..
                    })) => {
                        log::warn!("{peer_id:?}: {info:?}");

                    }
                    SwarmEvent::Behaviour(MyBehaviourEvent::Identify(identify::Event::Sent {
                        peer_id, ..
                    })) => {
                        log::warn!("Sent identify info to {peer_id:?}");
                        swarm.behaviour_mut().rendezvous.register(
                            rendezvous::Namespace::from_static("rendezvous"),
                            peer_id,
                            None,
                        );
                    }

                    SwarmEvent::Behaviour(MyBehaviourEvent::Rendezvous(
                        rendezvous::client::Event::Registered {
                            namespace,
                            ttl,
                            rendezvous_node,
                        },
                    )) => {
                        log::warn!(
                            "Registered for namespace '{}' at rendezvous point {} for the next {} seconds",
                            namespace,
                            rendezvous_node,
                            ttl
                        );
                    }
                    SwarmEvent::Behaviour(MyBehaviourEvent::Rendezvous(
                        rendezvous::client::Event::RegisterFailed(error),
                    )) => {
                        log::error!("Failed to register {}", error);
                    }

                    SwarmEvent::Behaviour(MyBehaviourEvent::Ping(ping::Event {
                        peer,
                        result: Ok(rtt),
                        ..
                    })) => {
                        match rtt {
                            libp2p::ping::Success::Ping{rtt: stt} => {
                                log::warn!("Ping to {} in {:?}", peer, stt);
                            },
                            libp2p::ping::Success::Pong{} => {

                            }
                        }

                    }
                    other => {
                        log::debug!("Unhandled {:?}", other);
                    }
            },
            _ = discover_tick.tick(), if cookie.is_some() => {}
                // swarm.behaviour_mut().rendezvous.discover(
                //     Some(rendezvous::Namespace::new(NAMESPACE.to_string()).unwrap()),
                //     cookie.clone(),
                //     None,
                //     rendezvous_point)
        }
    }
}
#+end_src

copy from https://github.com/PixelCoda/Thalamus

** authenticate with Kepair example

#+begin_src rust
pub fn create_transport(
    id_keys: &Keypair,
) -> Result<transport::Boxed<(PeerId, StreamMuxerBox)>, noise::Error> {
    // Setup the transport + multiplex + auth
    // Zinnia will hard-code this configuration initially.
    // We need to pick reasonable defaults that will allow Zinnia nodes to interoperate with
    // as many other libp2p nodes as possible.
    let tcp_transport = libp2p::dns::TokioDnsConfig::system(libp2p::tcp::tokio::Transport::new(
        libp2p::tcp::Config::new(),
    ))?
    .upgrade(upgrade::Version::V1Lazy)
    .authenticate(noise::Config::new(id_keys)?)
    .multiplex(upgrade::SelectUpgrade::new(
        yamux::Config::default(),
        libp2p::mplex::MplexConfig::default(),
    ))
    .timeout(std::time::Duration::from_secs(5))
    .boxed();
    Ok(tcp_transport)
}
#+end_src

copy from https://github.com/filecoin-station/zinnia


** libp2p with_other_transport usage

#+begin_src rust
#[allow(missing_debug_implementations)]
pub struct Relay<P: Provider + Sync> {
  swarm: Swarm<Behaviour>,
  db: Sql,
  provider: Box<P>,
}

impl<P: Provider + Sync> Relay<P> {
  pub fn new(
    pool: Sql,
    provider: P,
    port: u16,
    port_webrtc: u16,
    local_key_path: Option<String>,
    cert_path: Option<String>,
  ) -> Result<Self, Error> {
    let local_key = if let Some(path) = local_key_path {
      let path = Path::new(&path);
      read_or_create_identity(path).map_err(Error::ReadIdentityError)?
    } else {
      identity::Keypair::generate_ed25519()
    };

    let cert = if let Some(path) = cert_path {
      let path = Path::new(&path);
      read_or_create_certificate(path).map_err(Error::ReadCertificateError)?
    } else {
      Certificate::generate(&mut thread_rng()).unwrap()
    };

    info!(target: LOG_TARGET, peer_id = %PeerId::from(local_key.public()), "Relay peer id.");

    let mut swarm = libp2p::SwarmBuilder::with_existing_identity(local_key)
      .with_tokio()
      .with_tcp(tcp::Config::default(), noise::Config::new, yamux::Config::default)?
      .with_quic()
      .with_other_transport(|key| {
        Ok(webrtc::tokio::Transport::new(key.clone(), cert)
           .map(|(peer_id, conn), _| (peer_id, StreamMuxerBox::new(conn))))
      })
      .expect("Failed to create WebRTC transport")
      .with_behaviour(|key| {
        // Hash messages by their content. No two messages of the same content will be
        // propagated.
        let _message_id_fn = |message: &gossipsub::Message| {
          let mut s = DefaultHasher::new();
          message.data.hash(&mut s);
          gossipsub::MessageId::from(s.finish().to_string())
        };
        let gossipsub_config = gossipsub::ConfigBuilder::default()
          .heartbeat_interval(Duration::from_secs(constants::GOSSIPSUB_HEARTBEAT_INTERVAL_SECS)) // This is set to aid debugging by not cluttering the log space
          .validation_mode(gossipsub::ValidationMode::Strict) // This sets the kind of message validation. The default is Strict (enforce message signing)
        // TODO: Use this once we incorporate nonces in the message model?
        // .message_id_fn(message_id_fn) // content-address messages. No two messages of the same content will be propagated.
          .build()
          .map_err(|msg| io::Error::new(io::ErrorKind::Other, msg)).unwrap(); // Temporary hack because `build` does not return a proper `std::error::Error`.

        Behaviour {
          relay: relay::Behaviour::new(key.public().to_peer_id(), Default::default()),
          ping: ping::Behaviour::new(ping::Config::new()),
          identify: identify::Behaviour::new(identify::Config::new(
            "/torii-relay/0.0.1".to_string(),
            key.public(),
          )),
          gossipsub: gossipsub::Behaviour::new(
            gossipsub::MessageAuthenticity::Signed(key.clone()),
            gossipsub_config,
          )
            .unwrap(),
        }
      })?
      .with_swarm_config(|cfg| {
        cfg.with_idle_connection_timeout(Duration::from_secs(
          constants::IDLE_CONNECTION_TIMEOUT_SECS,
        ))
      })
      .build();

    // TCP
    let listen_addr_tcp = Multiaddr::from(Ipv4Addr::UNSPECIFIED).with(Protocol::Tcp(port));
    swarm.listen_on(listen_addr_tcp.clone())?;

    // UDP QUIC
    let listen_addr_quic =
      Multiaddr::from(Ipv4Addr::UNSPECIFIED).with(Protocol::Udp(port)).with(Protocol::QuicV1);
    swarm.listen_on(listen_addr_quic.clone())?;

    // WebRTC
    let listen_addr_webrtc = Multiaddr::from(Ipv4Addr::UNSPECIFIED)
      .with(Protocol::Udp(port_webrtc))
      .with(Protocol::WebRTCDirect);
    swarm.listen_on(listen_addr_webrtc.clone())?;

    // Clients will send their messages to the "message" topic
    // with a room name as the message data.
    // and we will forward those messages to a specific room - in this case the topic
    // along with the message data.
    swarm
      .behaviour_mut()
      .gossipsub
      .subscribe(&IdentTopic::new(constants::MESSAGING_TOPIC))
      .unwrap();

    Ok(Self { swarm, db: pool, provider: Box::new(provider) })
  }
}
#+end_src

copy from https://github.com/dojoengine/dojo

** tcp config

#+begin_src rust
pub async fn init_swarm() -> Result<Swarm<chain::Behaviour>, Box<dyn SError>> {
  let auth_keys = gen_ed25519(0);
  let mut swarm = libp2p::SwarmBuilder::with_existing_identity(auth_keys.clone())
    .with_tokio()
    .with_tcp(tcp::Config::default()
              .nodelay(true)
              .port_reuse(true)
              , noise::Config::new, yamux::Config::default)?
    .with_quic()
    .with_other_transport(|k| {
      tcp::tokio::Transport::new(tcp::Config::default().port_reuse(false).nodelay(true))
        .upgrade(Version::V1Lazy)
        .authenticate(NoiseConfig::new(k).unwrap())
        .multiplex(YamuxConfig::default())
    })?
    .with_other_transport(|k| {
      tcp::tokio::Transport::new(tcp::Config::default().port_reuse(false).nodelay(true))
        .upgrade(Version::V1)
        .authenticate(NoiseConfig::new(k).unwrap())
        .multiplex(YamuxConfig::default())
    })?
    .with_dns()?
    .with_relay_client(noise::Config::new, yamux::Config::default)?
    .with_behaviour(|k, relay_behaviour| chain::Behaviour::from(k.clone()))?
    .with_swarm_config(|c| c.with_idle_connection_timeout(Duration::from_secs(5)))
    .build();
  swarm.behaviour_mut()
    .kad
    .set_mode(Some(libp2p::kad::Mode::Server));
  let gst = gossipsub::IdentTopic::new("test-net");
  let fst = floodsub::Topic::new("chain");
  swarm.behaviour_mut().fs.subscribe(fst);
  swarm.behaviour_mut().gs.subscribe(&gst)?;
  // let mut stdin = std::io::BufReader::new(std::io::stdin()).lines();


  Ok(swarm)
}
#+end_src

copy from https://github.com/clpi/mbc

** libp2p gossipsub and libp2p_stream code example

#+begin_src rust

#[derive(thiserror::Error, Debug)]
pub enum SwarmError {
    #[error("duplicate dialing")]
    DuplicateDialing,
}

/// How long to keep a connection alive once it is idling.
const IDLE_CONN_TIMEOUT: Duration = Duration::from_secs(300);

impl Swarm {
    /// Builds a [`Swarm`] configured for use with Nomos on top of a tokio executor.
    //
    // TODO: define error types
    pub fn build(config: &SwarmConfig) -> Result<Self, Box<dyn Error>> {
        let keypair =
            libp2p::identity::Keypair::from(secp256k1::Keypair::from(config.node_key.clone()));
        let peer_id = PeerId::from(keypair.public());
        tracing::info!("libp2p peer_id:{}", peer_id);

        let mut swarm = libp2p::SwarmBuilder::with_existing_identity(keypair)
            .with_tokio()
            .with_quic()
            .with_dns()?
            .with_behaviour(|_| Behaviour::new(peer_id, config.gossipsub_config.clone()).unwrap())?
            .with_swarm_config(|c| c.with_idle_connection_timeout(IDLE_CONN_TIMEOUT))
            .build();

        swarm.listen_on(Self::multiaddr(config.host, config.port))?;

        Ok(Swarm { swarm })
    }

    /// Initiates a connection attempt to a peer
    pub fn connect(&mut self, peer_addr: Multiaddr) -> Result<ConnectionId, DialError> {
        let opt = DialOpts::from(peer_addr.clone());
        let connection_id = opt.connection_id();

        tracing::debug!("attempting to dial {peer_addr}. connection_id:{connection_id:?}",);
        self.swarm.dial(opt)?;
        Ok(connection_id)
    }

    /// Subscribes to a topic
    ///
    /// Returns true if the topic is newly subscribed or false if already subscribed.
    pub fn subscribe(&mut self, topic: &str) -> Result<bool, SubscriptionError> {
        self.swarm
            .behaviour_mut()
            .gossipsub
            .subscribe(&gossipsub::IdentTopic::new(topic))
    }

    pub fn broadcast(
        &mut self,
        topic: &str,
        message: impl Into<Vec<u8>>,
    ) -> Result<MessageId, PublishError> {
        self.swarm
            .behaviour_mut()
            .gossipsub
            .publish(gossipsub::IdentTopic::new(topic), message)
    }

    /// Unsubscribes from a topic
    ///
    /// Returns true if previously subscribed
    pub fn unsubscribe(&mut self, topic: &str) -> Result<bool, PublishError> {
        self.swarm
            .behaviour_mut()
            .gossipsub
            .unsubscribe(&gossipsub::IdentTopic::new(topic))
    }

    /// Returns a reference to the underlying [`libp2p::Swarm`]
    pub fn swarm(&self) -> &libp2p::Swarm<Behaviour> {
        &self.swarm
    }

    pub fn is_subscribed(&mut self, topic: &str) -> bool {
        let topic_hash = Self::topic_hash(topic);

        //TODO: consider O(1) searching by having our own data structure
        self.swarm
            .behaviour_mut()
            .gossipsub
            .topics()
            .any(|h| h == &topic_hash)
    }

    pub fn topic_hash(topic: &str) -> TopicHash {
        gossipsub::IdentTopic::new(topic).hash()
    }

    /// Returns a stream control that can be used to accept streams and establish streams to
    /// other peers.
    /// Stream controls can be cloned.
    pub fn stream_control(&self) -> Control {
        self.swarm.behaviour().stream.new_control()
    }

    pub fn multiaddr(ip: std::net::Ipv4Addr, port: u16) -> Multiaddr {
        multiaddr!(Ip4(ip), Udp(port), QuicV1)
    }
}

impl futures::Stream for Swarm {
    type Item = SwarmEvent<BehaviourEvent>;

    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
        Pin::new(&mut self.swarm).poll_next(cx)
    }
}

fn compute_message_id(message: &Message) -> MessageId {
    let mut hasher = Blake2b::<U32>::new();
    hasher.update(&message.data);
    MessageId::from(hasher.finalize().to_vec())
}

#[cfg(test)]
mod tests {
    use std::time::Duration;

    use futures::{AsyncReadExt, AsyncWriteExt, StreamExt};
    use libp2p::StreamProtocol;
    use rand::Rng;

    use crate::{Swarm, SwarmConfig};

    #[tokio::test]
    async fn stream() {
        // Init two swarms
        let (config1, mut swarm1) = init_swarm();
        let (_, mut swarm2) = init_swarm();
        let swarm1_peer_id = *swarm1.swarm().local_peer_id();

        // Dial to swarm1
        swarm2
            .connect(Swarm::multiaddr(config1.host, config1.port))
            .unwrap();

        // Prepare stream controls
        let mut stream_control1 = swarm1.stream_control();
        let mut stream_control2 = swarm2.stream_control();

        // Poll swarms to make progress
        tokio::spawn(async move { while (swarm1.next().await).is_some() {} });
        tokio::spawn(async move { while (swarm2.next().await).is_some() {} });

        // Make swarm1 accept incoming streams
        let protocol = StreamProtocol::new("/test");
        let mut incoming_streams = stream_control1.accept(protocol).unwrap();
        tokio::spawn(async move {
            // If a new stream is established, write bytes and close the stream.
            while let Some((_, mut stream)) = incoming_streams.next().await {
                stream.write_all(&[1, 2, 3, 4]).await.unwrap();
                stream.close().await.unwrap();
            }
        });

        // Wait until the connection is established
        tokio::time::sleep(Duration::from_secs(1)).await;

        // Establish a stream with swarm1 and read bytes
        let mut stream = stream_control2
            .open_stream(swarm1_peer_id, StreamProtocol::new("/test"))
            .await
            .unwrap();
        let mut buf = [0u8; 4];
        stream.read_exact(&mut buf).await.unwrap();
        assert_eq!(buf, [1, 2, 3, 4]);
    }

    fn init_swarm() -> (SwarmConfig, Swarm) {
        let config = SwarmConfig {
            host: std::net::Ipv4Addr::new(127, 0, 0, 1),
            port: rand::thread_rng().gen_range(10000..30000),
            ..Default::default()
        };
        let swarm = Swarm::build(&config).unwrap();
        (config, swarm)
    }
}
#+end_src

copy from https://github.com/logos-co/nomos-node


** convert libsecp256k1::SecretKey to libp2p_identity::secp256k1::Keypair

#+begin_src rust
/// Converts a `libsecp256k1::SecretKey` to a `libp2p_identity::secp256k1::Keypair`.
/// To do this, we serialize the secret key and create a new keypair from it.
#[inline]
pub fn secret_to_keypair(secret_key: &SecretKey) -> Keypair {
    let bytes = secret_key.serialize();

    let secret_key = libp2p_identity::secp256k1::SecretKey::try_from_bytes(bytes)
        .expect("Failed to create secret key");
    libp2p_identity::secp256k1::Keypair::from(secret_key).into()
}
#+end_src

copy from https://github.com/firstbatchxyz/dkn-compute-node

** request_response

#+begin_src rust
use libp2p::{
  request_response::{self, OutboundRequestId, ProtocolSupport, ResponseChannel},
};

pub(crate) struct EventLoop {
  swarm: Swarm<Behaviour>,
  command_receiver: mpsc::Receiver<Command>,
  event_sender: mpsc::Sender<Event>,
  pending_dial: HashMap<PeerId, oneshot::Sender<Result<(), Box<dyn Error + Send>>>>,
  pending_start_providing: HashMap<kad::QueryId, oneshot::Sender<()>>,
  pending_get_providers: HashMap<kad::QueryId, oneshot::Sender<HashSet<PeerId>>>,
  pending_request_file:
    HashMap<OutboundRequestId, oneshot::Sender<Result<Vec<u8>, Box<dyn Error + Send>>>>,
}

let request_id = self
  .swarm
  .behaviour_mut()
  .request_response
  .send_request(&peer, FileRequest(file_name));
self.pending_request_file.insert(request_id, sender);

self
  .swarm
  .behaviour_mut()
  .request_response
  .send_response(channel, FileResponse(file))
  .expect("Connection to peer to be still open.");

#[derive(NetworkBehaviour)]
struct Behaviour {
  request_response: request_response::cbor::Behaviour<FileRequest, FileResponse>,
  kademlia: kad::Behaviour<kad::store::MemoryStore>,
}
#+end_src


** libp2p quic implementation does not support pnet protocol

see [[https://github.com/libp2p/rust-libp2p/issues/3275][Add Support for Pnet on quic]]

** libp2p pnet protocol

#+begin_quote
Libp2p nodes configured with a pre-shared key can only communicate with other nodes with the same key.
#+end_quote

copy from [[https://docs.rs/libp2p/0.54.1/libp2p/pnet/index.html][Crate libp2p::pnet]]

#+begin_quote
对于联盟链的业务中搭建一个私有网络的 IPFS 集群还是很有必要的，私有网络集群允许 IPFS 节点只连接到拥有共享密钥的其他对等节点，网络中的节点不响应来自网络外节点的通信。
#+end_quote

copy from [[https://chain-code.github.io/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/ipfs/2021-06-02-ipfs%E7%A7%81%E6%9C%89%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA/][IPFS私有网络集群搭建]]


also see [[https://github.com/libp2p/specs/blob/master/pnet/Private-Networks-PSK-V1.md][Pre-shared Key Based Private Networks in libp2p]]


** libp2p dctur, relay server, rendezvous protocol, autoNAT

#+begin_quote
rendezvous is a protocol for peer discovery of all kinds (e.g. services, relays, etc). a "rendezvous" peer is typically a well-know peer at a public fixed address. typically, when a peer starts up it connects to a set of fixed rendezvous servers to query for other peers and to also register itself so that other peers may find it. the rendezvous server acts as a centralized routing table/directory. one popular use for rendezvous servers is for them to advertise peers subscribed to a topic in a pub-sub network. this is how some blockchain networks bootstrap. rendezvous servers have also used pub-sub among themselves to gossip advertising data so that they all advertise the same information to peers.

NOTE: this isn't very "decentralized" but is very handy and is how most of the p2p networks using libp2p "bootstrap". use of rendezvous servers forms a hub-and-spoke network topology, even if briefly. if you're goal is to create metastable p2p networks with no fixed infrastructure then rendezvous is not for you and you'll have to use other peer discovery methods.

relay server is when a publicly available libp2p peer relays traffic from one peer to another. this is typically done when one or both peers are behind a NAT and do not have publicly routable IP addresses.

dcutr is a method for using a relay server as a signaling server to do hole punching through a NAT so that a direct connection between peers is possible even when one or both peers are behind a NAT.

autonat is a protocol/method that a peer uses to discover if it is behind a NAT. it enables asking other peers to dial back to the initiating peer. this is often used in conjunction with a relay server that receives the dial back and relays the traffic if the initiating peer is behind a NAT.

To wrap your head around this better, you have to remember that all libp2p peers typically act as servers as well as clients. Meaning they make outbound dials to other peers as well as accept inbound dials from other peers. When a peer is behind a NAT it typically doesn't have a public routable IP address. the best way for it to accept an inbound dial is to first connect to a relay server and get a reservation for accepting inbound dials on its behalf. Once an inbound dial happens, the relay server can continue to relay traffic or dcutr can be attempted to punch a hole in the NAT and establish a direct connection between the NAT'd peer and the dialing peer.
#+end_quote

copy from [[https://stackoverflow.com/questions/78431030/difference-between-dctur-relay-server-rendezvous-protocol-signalling-server-a][Difference between dctur, relay server, rendezvous protocol, signalling server and a tracking server? in terms of peer to peer network]]


** libp2p performance test

see [[https://observablehq.com/@libp2p-workspace/libp2p-perf-blog-post-1][libp2p Performance]]

** rust libp2p project

https://github.com/renegade-fi/renegade
https://github.com/ethersync/ethersync
https://github.com/p2panda/aquadoggo
https://github.com/domo-iot/libp2p-rust-dht
https://github.com/Actyx/Actyx
https://github.com/Sherlock-Holo/private_share
https://github.com/ipfs-rust/ipfs-embed
https://github.com/molyee-tech/syncy
https://github.com/project-takoyaki/project-takoyaki-botnet
https://github.com/gcp-development/ipfs-private-network
https://github.com/brian-dawn/lab-monitor
https://github.com/clpi/mbc


** libp2p perf protocol

see [[https://observablehq.com/@libp2p-workspace/libp2p-perf-blog-post-1][libp2p Performance]]

[[https://github.com/libp2p/test-plans][Interoperability/end to end test-plans & performance benchmarking for libp2p]]

[[https://discuss.libp2p.io/t/rough-stress-metrics-for-gossipsub/2223][Rough stress metrics for Gossipsub]]


** libp2p perf command line example

*** clone the rust-libp2p repo, and build

#+begin_src shell
git clone https://github.com/libp2p/rust-libp2p
cd rust-libp2p
cargo build
$ ./target/debug/perf -h
Usage: perf [OPTIONS]

Options:
      --server-address <SERVER_ADDRESS>
      --transport <TRANSPORT>
      --upload-bytes <UPLOAD_BYTES>
      --download-bytes <DOWNLOAD_BYTES>
      --run-server                       Run in server mode
  -h, --help                             Print help
#+end_src

*** Run in server mode:

#+begin_src shell
./target/debug/perf --server-address '127.0.0.1:8080' --run-server
#+end_src

*** In another terminal, try to upload/download 100MB:

#+begin_src shell
./target/debug/perf --server-address '127.0.0.1:8080' --transport tcp --upload-bytes 104857600 --download-bytes 104857600
#+end_src

** To simulate network latency and packet loss, we can use pfctl and dnctl

*** enable the packet filter:

#+begin_src shell
sudo pfctl -E
#+end_src

*** Then create a custom anchor in pf:

#+begin_src shell
cat /etc/pf.conf && echo "dummynet-anchor \"libp2p\"" && echo "anchor \"libp2p\"" | sudo pfctl -f -
#+end_src

*** Pipe the traffic to dummynet:

#+begin_src shell
echo "dummynet in quick proto tcp from any to any port 8080 pipe 1" | sudo pfctl -a libp2p -f -
#+end_src

*** Simulate the network latency:

#+begin_src shell
sudo dnctl pipe 1 config delay 10ms
#+end_src

*** Benchmark again, client:

#+begin_src shell
./target/debug/perf --server-address '127.0.0.1:8080' --transport tcp --upload-bytes 104857600 --download-bytes 104857600
#+end_src


*** Simulate the packet loss:

#+begin_src shell
$ sudo dnctl pipe 1 config plr 0.01

$ sudo dnctl list
00001: unlimited    0 ms   50 sl.plr 0.010000 1 queues (1 buckets) droptail
mask: 0x00 0x00000000/0x0000 -> 0x00000000/0x0000
4BKT Prot ___Source IP/port____ ____Dest. IP/port____ Tot_pkt/bytes Pkt/Byte Drp
mask: 0x00 0x00000000/0x0000 -> 0x00000000/0x0000
BKT Prot ___Source IP/port____ ____Dest. IP/port____ Tot_pkt/bytes Pkt/Byte Drp
0 tcp        127.0.0.1/63691       127.0.0.1/8080  1011241 490303519  0    0 9463
#+end_src

*** client:

#+begin_src shell
./target/debug/perf --server-address '127.0.0.1:8080' --transport tcp --upload-bytes 104857600 --download-bytes 104857600
#+end_src

copy from [[https://quantonganh.com/2023/10/27/libp2p-perf-benchmark.md][libp2p performance benchmarking]]


** request_response multiple protcol support

copy from mbc

#+begin_src rust
fn req_resp(k: &PeerId) -> request_response::cbor::Behaviour<LocalChainReq, ChainResponse> {
    request_response::cbor::Behaviour::<LocalChainReq, ChainResponse>::new(
        [
            (StreamProtocol::new("/chain/client/1"), ProtocolSupport::Outbound),
            (StreamProtocol::new("/chain/1"), ProtocolSupport::Full),
            (StreamProtocol::new("/chain/server/1"), ProtocolSupport::Inbound)
        ],
        request_response::Config::default(),
    )
}
#+end_src

** dns ResolverConfig

** toggle

** allow_block_list

** keepalive deprecated

#+begin_quote
Deprecate KeepAlive::Until. Individual protocols should not keep connections alive for longer than necessary. Users should use swarm::Config::idle_connection_timeout instead. See PR 4656.
#+end_quote

copy from https://github.com/libp2p/rust-libp2p/blob/master/swarm/CHANGELOG.md

** libp2p PnetConfig project

https://github.com/ipfs-rust/ipfs-embed
https://github.com/electricherd/audiobookfinder
https://github.com/project-takoyaki/project-takoyaki-botnet
https://github.com/ChainSafe/forest


** libp2p::request_response::Behaviour::send_request

#+begin_src rust
pub fn send_request(&mut self, peer: &PeerId, request: TCodec::Request) -> OutboundRequestId {
    let request_id = self.next_outbound_request_id();
    let request = OutboundMessage {
        request_id,
        request,
        protocols: self.outbound_protocols.clone(),
    };

    if let Some(request) = self.try_send_request(peer, request) {
        self.pending_events.push_back(ToSwarm::Dial {
            opts: DialOpts::peer_id(*peer).build(),
        });
        self.pending_outbound_requests
            .entry(*peer)
            .or_default()
            .push(request);
    }

    request_id
}

/// Returns the next outbound request ID.
fn next_outbound_request_id(&mut self) -> OutboundRequestId {
    let request_id = self.next_outbound_request_id;
    self.next_outbound_request_id.0 += 1;
    request_id
}
#+end_src

The _+= 1_ means that request_response is sent one by one.


** kad behaviour


#+begin_quote
Kademlia 网络协议

Kademlia 是一种分布式哈希表协议和算法，用于构建去中心化的对等网络，核心思想是通过分布式的网络结构来实现高效的数据查找和存储。在这个学习项目里，Kademlia 作为 libp2p 中的 NetworkBehaviour的组成。

以下这些函数或方法是根据 Kademlia 网络协议设计的，它们实现了基本的网络操作，包括获取数据记录、获取数据提供者、存储数据记录和开始提供数据等功能（这里只展示了项目中用到的函数，常用函数可以看libp2p Kademlia DHT 规范，更多函数可见如下图中的源码部分）。

1. get_record

kademlia.get_record(key, Quorum::One);

    作用： 从 Kademlia 网络中获取与指定 key 相关的记录。
    参数：
        key: 要获取记录的键。
        Quorum::One: 获取记录时所需的一致性要求，这里是指只需要从一个节点获取记录即可。
    实现逻辑：
        根据 Kademlia 协议，节点首先根据 key 计算出其对应的 K-bucket 或者具体的节点 ID，然后向网络中查找负责该 key 的节点。
        节点通过网络查询和消息传递机制，从负责节点处获取存储的记录。
        返回获取到的记录或者执行相应的处理逻辑。

2. get_providers

kademlia.get_providers(key);

    作用： 获取能够提供与指定 key 相关数据的节点信息（即数据的提供者）。
    参数：
        key: 要获取提供者信息的数据的键。
    实现逻辑：
        类似于 get_record，节点根据 key 计算出其对应的 K-bucket 或者节点 ID。
        节点向网络发送查询请求，询问哪些节点能够提供与 key 相关的数据。
        返回能够提供数据的节点列表或者执行相应的处理逻辑。

3. put_record

let record = Record {
    key,
    value,
    publisher: None,
    expires: None,
};
kademlia.put_record(record, Quorum::One).expect("Failed to store record locally.");

    作用： 将指定的记录存储到 Kademlia 网络中。
    参数：
        record: 包含要存储的数据信息的记录对象，包括 key（键）、value（值）、publisher（发布者，可能为空）、expires（过期时间，可能为空）等字段。
        Quorum::One: 存储记录时的一致性要求，这里是指只需要将记录存储在一个节点即可。
    实现逻辑：
        节点根据 key 计算出对应的 K-bucket 或节点 ID。
        节点将 record 发送给负责存储该 key 的节点，并根据指定的一致性要求存储副本。
        返回存储成功或失败的结果，或者执行相应的处理逻辑。

4. start_providing

kademlia.start_providing(key).expect("Failed to start providing key");

    作用： 在 Kademlia 网络中开始提供指定 key 的数据。
    参数：
        key: 要开始提供的数据的键。
    实现逻辑：
        节点将 key 注册为它可以提供的数据标识。
        当其他节点查询或需要该 key 的数据时，该节点将响应并提供相应的数据。
        返回启动提供成功或失败的结果，或者执行相应的处理逻辑。
#+end_quote

copy from [[https://blog.csdn.net/ResumeProject/article/details/140108419][p2p、分布式，区块链笔记: 通过libp2p的Kademlia网络协议实现kv-store_kademlia协议]]

*** get_closest_peers and get_closest_local_peers function

#+begin_quote
pub fn get_closest_peers<K>(&mut self, key: K) -> QueryId
where
    K: Into<Key<K>> + Into<Vec<u8>> + Clone,
Initiates an iterative query for the closest peers to the given key.

The result of the query is delivered in a [Event::OutboundQueryProgressed{QueryResult::GetClosestPeers}].

source
pub fn get_closest_local_peers<'a, K>(
    &'a mut self,
    key: &'a Key<K>,
) -> impl Iterator<Item = Key<PeerId>> + 'a
where
    K: Clone,
Returns closest peers to the given key; takes peers from local routing table only.
#+end_quote


** handle OutgoingConnectionError

#+begin_src rust
use libp2p::core::{DialError, Multiaddr, TransportError};

const BOOT_ADDRESS: &str = "/ip4/127.0.0.1/tcp/8080"; // Replace with your actual BOOT_ADDRESS

match event {
    SwarmEvent::OutgoingConnectionError { error, .. } => {
        match error {
            DialError::Transport(error_list) => {

                // Use `any` to check if any Multiaddr matches BOOT_ADDRESS
                let found_boot_address = error_list.iter().any(|(multiaddr, _)| multiaddr.to_string() == BOOT_ADDRESS);

                if found_boot_address {
                    println!("Found error related to BOOT_ADDRESS");
                }
            }
            _ => {}
        }
    }
}

#+end_src

code with chatgpt

** libp2p discussion
https://github.com/libp2p/rust-libp2p/discussions/2025


** kad peer_id set

#+begin_src rust
pub fn known_peers(&mut self) -> HashSet<PeerId> {
    let mut peers = HashSet::new();
    if let Some(k) = self.kademlia.as_mut() {
        for b in k.kbuckets() {
            for e in b.iter() {
                if !peers.contains(e.node.key.preimage()) {
                    peers.insert(*e.node.key.preimage());
                }
            }
        }
    }
    peers
}
#+end_src